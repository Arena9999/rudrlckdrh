<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>CVA 실시간 측정</title>
  <style>
    #canvas {
      position: absolute;
      left: 0;
      top: 0;
    }
    #video {
      transform: scaleX(-1); /* 좌우 반전 */
      display: none;
    }
    #status {
      position: absolute;
      top: 10px;
      left: 10px;
      font-size: 24px;
      font-weight: bold;
      color: red;
      background: rgba(255,255,255,0.6);
      padding: 5px 10px;
      border-radius: 5px;
    }
  </style>
</head>
<body>
<video id="video" width="640" height="480" autoplay playsinline></video>
<canvas id="canvas" width="640" height="480"></canvas>
<div id="status">CVA: --, 상태: --</div>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const statusEl = document.getElementById('status');

function calculateCVA(shoulder, ear) {
  const dx = ear.x - shoulder.x;
  const dy = ear.y - shoulder.y;
  const angle = Math.atan2(dy, dx) * 180 / Math.PI;
  return Math.abs(90 - Math.abs(angle));
}

// Mediapipe Pose 설정
const pose = new Pose({
  locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/${file}`
});
pose.setOptions({
  modelComplexity: 1,
  smoothLandmarks: true,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});
pose.onResults(onResults);

// 카메라 시작
navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
  video.srcObject = stream;
});

// 결과 처리
function onResults(results) {
  ctx.save();
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.translate(canvas.width, 0);  // 캔버스 오른쪽으로 이동
  ctx.scale(-1, 1);
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  if (results.poseLandmarks) {
    const lm = results.poseLandmarks;

    const shoulder_r = lm[POSE_LANDMARKS.RIGHT_SHOULDER];
    const ear_r = lm[POSE_LANDMARKS.RIGHT_EAR];
    const shoulder_l = lm[POSE_LANDMARKS.LEFT_SHOULDER];
    const ear_l = lm[POSE_LANDMARKS.LEFT_EAR];

    const cva_r = calculateCVA(shoulder_r, ear_r);
    const cva_l = calculateCVA(shoulder_l, ear_l);
    const cva_avg = (cva_r + cva_l) / 2;
    const status = cva_avg >= 25 ? "Forward Head" : "Normal";

    statusEl.innerText = `CVA: ${cva_avg.toFixed(1)}°, 상태: ${status}`;
    ctx.strokeStyle = cva_avg >= 25 ? "red" : "green";
    ctx.lineWidth = 3;

    ctx.beginPath();
    ctx.moveTo(shoulder_r.x * canvas.width, shoulder_r.y * canvas.height);
    ctx.lineTo(ear_r.x * canvas.width, ear_r.y * canvas.height);
    ctx.stroke();

    ctx.beginPath();
    ctx.moveTo(shoulder_l.x * canvas.width, shoulder_l.y * canvas.height);
    ctx.lineTo(ear_l.x * canvas.width, ear_l.y * canvas.height);
    ctx.stroke();

    // Mediapipe 랜드마크 그리기
    drawConnectors(ctx, lm, POSE_CONNECTIONS, {color: 'white', lineWidth: 2});
    drawLandmarks(ctx, lm, {color: 'blue', lineWidth: 1});
  }

  ctx.restore();
}

// 비디오 프레임마다 Pose 처리
async function detectPose() {
  await pose.send({image: video});
  requestAnimationFrame(detectPose);
}
video.onloadeddata = () => {
  detectPose();
};
</script>
</body>
</html>